
@article{alessandroMachineLearningSpaced2021,
  title = {Machine {{Learning}} for {{Spaced Repetition}} in {{Human Learning}}},
  author = {Alessandro, Bianchi and Sophie, De Becker and Emanuel, Vasquez},
  year = {2021},
  pages = {5},
  abstract = {In this report, we analyse how an exponential human learning model can be used to predict the learning rate of students using the Ari9000 application. In particular, we apply gradient descent and online gradient descent to fit the exponential model. We compare a least squares loss, a regularized loss, and a maximum likelihood estimation. Overall, simple baseline models performed slightly better in terms of prediction accuracy than the exponential model. This later model is limited by how well the features can describe a student's surrounding given available data. Even if our engineered features failed to produce high predictive accuracy, the resulting half-life values could still be useful for creating improved learning schemes.},
  langid = {english},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2021/2021_Machine Learning for Spaced Repetition in Human Learning_Alessandro et al.pdf}
}

@article{andersonIntegratedTheoryMind2004,
  title = {An {{Integrated Theory}} of the {{Mind}}.},
  author = {Anderson, John R. and Bothell, Daniel and Byrne, Michael D. and Douglass, Scott and Lebiere, Christian and Qin, Yulin},
  year = {2004},
  journal = {Psychological Review},
  volume = {111},
  number = {4},
  pages = {1036--1060},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.111.4.1036},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2004/2004_An Integrated Theory of the Mind_Anderson et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2004/2004_An Integrated Theory of the Mind_Anderson et al2.pdf}
}

@incollection{androulakisDynamicProgrammingStochastic2009,
  title = {Dynamic {{Programming}}: {{Stochastic Shortest Path Problems}}},
  shorttitle = {Dynamic {{Programming}}},
  booktitle = {Encyclopedia of {{Optimization}}},
  author = {Androulakis, Ioannis P.},
  editor = {Floudas, Christodoulos A. and Pardalos, Panos M.},
  year = {2009},
  pages = {869--873},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-0-387-74759-0_152},
  isbn = {978-0-387-74758-3 978-0-387-74759-0},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Book Section/2009/2009_Dynamic Programming_Androulakis.pdf}
}

@article{bahrickRetentionSpanishVocabulary1987,
  title = {Retention of {{Spanish}} Vocabulary over 8 Years.},
  author = {Bahrick, Harry P. and Phelphs, Elizabeth},
  year = {1987},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {13},
  number = {2},
  pages = {344--349},
  issn = {0278-7393},
  doi = {10.1037/0278-7393.13.2.344},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1987/1987_Retention of Spanish vocabulary over 8 years_Bahrick_Phelphs.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1987/1987_Retention of Spanish vocabulary over 8 years_Bahrick_Phelphs2.pdf}
}

@article{balotaExpandedRetrievalPractice,
  title = {Is {{Expanded Retrieval Practice}} a {{Superior Form}} of {{Spaced Retrieval}}? {{A Critical Review}} of the {{Extant Literature}}},
  author = {Balota, David A and Duchek, Janet M and Logan, Jessica M},
  pages = {23},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/undefined/Is Expanded Retrieval Practice a Superior Form of Spaced Retrieval_Balota et al.pdf}
}

@article{bertsekasAnalysisStochasticShortest1991,
  title = {An {{Analysis}} of {{Stochastic Shortest Path Problems}}},
  author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
  year = {1991},
  month = aug,
  journal = {Mathematics of Operations Research},
  volume = {16},
  number = {3},
  pages = {580--595},
  issn = {0364-765X, 1526-5471},
  doi = {10.1287/moor.16.3.580},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1991/1991_An Analysis of Stochastic Shortest Path Problems_Bertsekas_Tsitsiklis.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1991/1991_An Analysis of Stochastic Shortest Path Problems_Bertsekas_Tsitsiklis2.pdf}
}

@book{bertsekasReinforcementLearningOptimal2019,
  title = {Reinforcement Learning and Optimal Control},
  author = {Bertsekas, Dimitri P.},
  year = {2019},
  edition = {2nd printing (includes editorial revisions)},
  publisher = {{Athena Scientific}},
  address = {{Belmont, Massachusetts}},
  isbn = {978-1-886529-39-7},
  langid = {english},
  file = {/Users/jarrettye/Zotero/storage/LBTICR27/Bertsekas - 2019 - Reinforcement learning and optimal control.pdf}
}

@article{bjorkNewTheoryDisuse1992,
  title = {A New Theory of Disuse and an Old Theory of Stimulus Fluctuation},
  author = {Bjork, Robert A and Bjork, Elizabeth L and others},
  year = {1992},
  journal = {From learning processes to cognitive processes: Essays in honor of William K. Estes},
  volume = {2},
  pages = {35--67},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1992/1992_A new theory of disuse and an old theory of stimulus fluctuation_Bjork et al.pdf}
}

@article{branwenSpacedRepetitionEfficient2009,
  title = {Spaced {{Repetition}} for {{Efficient Learning}}},
  author = {Branwen, Gwern},
  year = {2009},
  month = mar,
  abstract = {Efficient memorization using the spacing effect: literature review of widespread applicability, tips on use \& what it's good for.},
  copyright = {https://creativecommons.org/publicdomain/zero/1.0/},
  langid = {american},
  file = {/Users/jarrettye/Zotero/storage/RXPSLXI8/Branwen - 2009 - Spaced Repetition for Efficient Learning.html}
}

@article{carpenterUsingTestsEnhance2009,
  title = {Using Tests to Enhance 8th Grade Students' Retention of {{U}}.{{S}}. History Facts},
  author = {Carpenter, Shana K. and Pashler, Harold and Cepeda, Nicholas J.},
  year = {2009},
  month = sep,
  journal = {Applied Cognitive Psychology},
  volume = {23},
  number = {6},
  pages = {760--771},
  issn = {08884080, 10990720},
  doi = {10.1002/acp.1507},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2009/2009_Using tests to enhance 8th grade students' retention of U_Carpenter et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2009/2009_Using tests to enhance 8th grade students' retention of U_Carpenter et al2.pdf}
}

@article{cepedaDistributedPracticeVerbal2006,
  title = {Distributed Practice in Verbal Recall Tasks: {{A}} Review and Quantitative Synthesis.},
  shorttitle = {Distributed Practice in Verbal Recall Tasks},
  author = {Cepeda, Nicholas J. and Pashler, Harold and Vul, Edward and Wixted, John T. and Rohrer, Doug},
  year = {2006},
  journal = {Psychological Bulletin},
  volume = {132},
  number = {3},
  pages = {354--380},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/0033-2909.132.3.354},
  abstract = {The authors performed a meta-analysis of the distributed practice effect to illuminate the effects of temporal variables that have been neglected in previous reviews. This review found 839 assessments of distributed practice in 317 experiments located in 184 articles. Effects of spacing (consecutive massed presentations vs. spaced learning episodes) and lag (less spaced vs. more spaced learning episodes) were examined, as were expanding interstudy interval (ISI) effects. Analyses suggest that ISI and retention interval operate jointly to affect final-test retention; specifically, the ISI producing maximal retention increased as retention interval increased. Areas needing future research and theoretical implications are discussed.},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2006/2006_Distributed practice in verbal recall tasks_Cepeda et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2006/2006_Distributed practice in verbal recall tasks_Cepeda et al2.pdf}
}

@article{cepedaSpacingEffectsLearning2008,
  title = {Spacing {{Effects}} in {{Learning}}: {{A Temporal Ridgeline}} of {{Optimal Retention}}},
  shorttitle = {Spacing {{Effects}} in {{Learning}}},
  author = {Cepeda, Nicholas J. and Vul, Edward and Rohrer, Doug and Wixted, John T. and Pashler, Harold},
  year = {2008},
  month = nov,
  journal = {Psychological Science},
  volume = {19},
  number = {11},
  pages = {1095--1102},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2008.02209.x},
  abstract = {To achieve enduring retention, people must usually study information on multiple occasions. How does the timing of study events affect retention? Prior research has examined this issue only in a spotty fashion, usually with very short time intervals. In a study aimed at characterizing spacing effects over significant durations, more than 1,350 individuals were taught a set of facts and\textemdash after a gap of up to 3.5 months\textemdash given a review. A final test was administered at a further delay of up to 1 year. At any given test delay, an increase in the interstudy gap at first increased, and then gradually reduced, final test performance. The optimal gap increased as test delay increased. However, when measured as a proportion of test delay, the optimal gap declined from about 20 to 40\% of a 1-week test delay to about 5 to 10\% of a 1-year test delay. The interaction of gap and test delay implies that many educational practices are highly inefficient.},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2008/2008_Spacing Effects in Learning_Cepeda et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2008/2008_Spacing Effects in Learning_Cepeda et al2.pdf}
}

@article{choffinDAS3HModelingStudent2019,
  title = {{{DAS3H}}: {{Modeling Student Learning}} and {{Forgetting}} for {{Optimally Scheduling Distributed Practice}} of {{Skills}}},
  shorttitle = {{{DAS3H}}},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine and Vie, Jill-J{\^e}nn},
  year = {2019},
  month = may,
  journal = {arXiv:1905.06873 [cs, stat]},
  eprint = {1905.06873},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Spaced repetition is among the most studied learning strategies in the cognitive science literature. It consists in temporally distributing exposure to an information so as to improve long-term memorization. Providing students with an adaptive and personalized distributed practice schedule would benefit more than just a generic scheduler. However, the applicability of such adaptive schedulers seems to be limited to pure memorization, e.g. flashcards or foreign language learning. In this article, we first frame the research problem of optimizing an adaptive and personalized spaced repetition scheduler when memorization concerns the application of underlying multiple skills. To this end, we choose to rely on a student model for inferring knowledge state and memory dynamics on any skill or combination of skills. We argue that no knowledge tracing model takes both memory decay and multiple skill tagging into account for predicting student performance. As a consequence, we propose a new student learning and forgetting model suited to our research problem: DAS3H builds on the additive factor models and includes a representation of the temporal distribution of past practice on the skills involved by an item. In particular, DAS3H allows the learning and forgetting curves to differ from one skill to another. Finally, we provide empirical evidence on three real-world educational datasets that DAS3H outperforms other state-of-the-art EDM models. These results suggest that incorporating both item-skill relationships and forgetting effect improves over student models that consider one or the other.},
  archiveprefix = {arXiv},
  keywords = {_tablet,Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Statistics - Applications,Statistics - Machine Learning},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2019/2019_DAS3H_Choffin et al.pdf;/Users/jarrettye/Zotero/storage/DQWF23IY/1905.html}
}

@article{choPropertiesNeuralMachine2014,
  title = {On the {{Properties}} of {{Neural Machine Translation}}: {{Encoder-Decoder Approaches}}},
  shorttitle = {On the {{Properties}} of {{Neural Machine Translation}}},
  author = {Cho, Kyunghyun and {van Merrienboer}, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  year = {2014},
  month = oct,
  journal = {arXiv:1409.1259 [cs, stat]},
  eprint = {1409.1259},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Statistics - Machine Learning},
  file = {/Users/jarrettye/Zotero/storage/6UBFVN6K/Cho et al. - 2014 - On the Properties of Neural Machine Translation E.pdf;/Users/jarrettye/Zotero/storage/CAWP4SN2/1409.html}
}

@incollection{delaneySpacingTestingEffects2010,
  title = {Spacing and {{Testing Effects}}},
  booktitle = {Psychology of {{Learning}} and {{Motivation}}},
  author = {Delaney, Peter F. and Verkoeijen, Peter P.J.L. and Spirgel, Arie},
  year = {2010},
  volume = {53},
  pages = {63--147},
  publisher = {{Elsevier}},
  doi = {10.1016/S0079-7421(10)53003-2},
  isbn = {978-0-12-380906-3},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Book Section/2010/2010_Spacing and Testing Effects_Delaney et al.pdf}
}

@article{dietterichApproximateStatisticalTests1998,
  title = {Approximate {{Statistical Tests}} for {{Comparing Supervised Classification Learning Algorithms}}},
  author = {Dietterich, Thomas G.},
  year = {1998},
  month = oct,
  journal = {Neural Computation},
  volume = {10},
  number = {7},
  pages = {1895--1923},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976698300017197},
  abstract = {This article reviews five approximate statistical tests for determining whether one learning algorithm outperforms another on a particular learning task. These test sare compared experimentally to determine their probability of incorrectly detecting a difference when no difference exists (type I error). Two widely used statistical tests are shown to have high probability of type I error in certain situations and should never be used: a test for the difference of two proportions and a paired-differences t test based on taking several random train-test splits. A third test, a paired-differences t test based on 10-fold cross-validation, exhibits somewhat elevated probability of type I error. A fourth test, McNemar's test, is shown to have low type I error. The fifth test is a new test, 5 \texttimes{} 2 cv, based on five iterations of twofold cross-validation. Experiments show that this test also has acceptable type I error. The article also measures the power (ability to detect algorithm differences when they do exist) of these tests. The cross-validated t test is the most powerful. The 5\texttimes 2 cv test is shown to be slightly more powerful than McNemar's test. The choice of the best test is determined by the computational cost of running the learning algorithm. For algorithms that can be executed only once, Mc-Nemar's test is the only test with acceptable type I error. For algorithms that can be executed 10 times, the 5 \texttimes{} 2 cv test is recommended, because it is slightly more powerful and because it directly measures variation due to the choice of training set.},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1998/1998_Approximate Statistical Tests for Comparing Supervised Classification Learning_Dietterich.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1998/1998_Approximate Statistical Tests for Comparing Supervised Classification Learning_Dietterich2.pdf}
}

@article{donovanMetaanalyticReviewDistribution1999,
  title = {A Meta-Analytic Review of the Distribution of Practice Effect: {{Now}} You See It, Now You Don't.},
  shorttitle = {A Meta-Analytic Review of the Distribution of Practice Effect},
  author = {Donovan, John J. and Radosevich, David J.},
  year = {1999},
  journal = {Journal of Applied Psychology},
  volume = {84},
  number = {5},
  pages = {795--805},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1854},
  doi = {10.1037/0021-9010.84.5.795},
  abstract = {The present review examined the relationship between conditions of massed practice and spaced practice with respect to task performance. A meta-analysis of 63 studies with 112 effect sizes yielded an overall mean weighted effect size of 0.46, indicating that individuals in spaced practice conditions performed significantly higher than those in massed practice conditions. Subsequent analyses, however, suggested that the nature of the task being practiced, the intertrial time interval, and the interaction between these two variables significantly moderated the relationship between practice conditions and performance. In addition, significantly higher effect sizes were found in studies with low methodological rigor as compared with those studies higher in rigor. Directions for future research and applications of the findings are discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Achievement,Distributed Practice,Intertrial Interval,Massed Practice,Methodology,Performance,Retention,Task Complexity},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1999/1999_A meta-analytic review of the distribution of practice effect_Donovan_Radosevich.pdf;/Users/jarrettye/Zotero/storage/56LRIZHG/1999-01454-012.html}
}

@book{ebbinghausMemoryContributionExperimental1913,
  title = {Memory: {{A}} Contribution to Experimental Psychology.},
  shorttitle = {Memory},
  author = {Ebbinghaus, Hermann},
  translator = {Ruger, Henry A. and Bussenius, Clara E.},
  year = {1913},
  publisher = {{Teachers College Press}},
  address = {{New York}},
  doi = {10.1037/10011-000},
  langid = {english}
}

@article{hochreiterLongShortTermMemory1997,
  title = {Long {{Short-Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  year = {1997},
  month = nov,
  journal = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  file = {/Users/jarrettye/Zotero/storage/PGEB4WP5/neco.1997.9.8.1735.pdf.pdf}
}

@inproceedings{hunzikerTeachingMultipleConcepts2019,
  title = {Teaching Multiple Concepts to a Forgetful Learner},
  booktitle = {Advances in Neural Information Processing Systems 32: {{Annual}} Conference on Neural Information Processing Systems 2019, {{NeurIPS}} 2019, December 8-14, 2019, Vancouver, {{BC}}, Canada},
  author = {Hunziker, Anette and Chen, Yuxin and Aodha, Oisin Mac and Rodriguez, Manuel Gomez and Krause, Andreas and Perona, Pietro and Yue, Yisong and Singla, Adish},
  editor = {Wallach, Hanna M. and Larochelle, Hugo and Beygelzimer, Alina and {d'Alch{\'e}-Buc}, Florence and Fox, Emily B. and Garnett, Roman},
  year = {2019},
  pages = {4050--4060},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/nips/Hunziker0AR0PYS19.bib},
  timestamp = {Thu, 14 Oct 2021 10:01:41 +0200},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2019/2019_Teaching multiple concepts to a forgetful learner_Hunziker et al2.pdf}
}

@incollection{jonesPredictingImprovingMemory2016,
  title = {Predicting and {{Improving Memory Retention}}: {{Psychological Theory Matters}} in the {{Big Data Era}}},
  shorttitle = {Predicting and {{Improving Memory Retention}}},
  booktitle = {Big {{Data}} in {{Cognitive Science}}},
  editor = {Jones, Michael N.},
  year = {2016},
  month = nov,
  edition = {Zeroth},
  pages = {43--73},
  publisher = {{Psychology Press}},
  address = {{New York, NY : Routledge, 2016. |}},
  doi = {10.4324/9781315413570-8},
  isbn = {978-1-315-41357-0},
  langid = {english},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Book Section/2016/2016_Predicting and Improving Memory Retention.pdf}
}

@article{kelleyMakingLongtermMemories2013,
  title = {Making Long-Term Memories in Minutes: A Spaced Learning Pattern from Memory Research in Education},
  shorttitle = {Making Long-Term Memories in Minutes},
  author = {Kelley, Paul and Whatson, Terry},
  year = {2013},
  journal = {Frontiers in Human Neuroscience},
  volume = {7},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2013.00589},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2013/2013_Making long-term memories in minutes_Kelley_Whatson.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2013/2013_Making long-term memories in minutes_Kelley_Whatson2.pdf}
}

@article{khajahMaximizingStudentsRetention2014,
  title = {Maximizing {{Students}}' {{Retention}} via {{Spaced Review}}: {{Practical Guidance From Computational Models}} of {{Memory}}},
  shorttitle = {Maximizing {{Students}}' {{Retention}} via {{Spaced Review}}},
  author = {Khajah, Mohammad M. and Lindsey, Robert V. and Mozer, Michael C.},
  year = {2014},
  month = jan,
  journal = {Topics in Cognitive Science},
  volume = {6},
  number = {1},
  pages = {157--169},
  issn = {17568757},
  doi = {10.1111/tops.12077},
  abstract = {During each school semester, students face an onslaught of material to be learned. Students work hard to achieve initial mastery of the material, but when they move on, the newly learned facts, concepts, and skills degrade in memory. Although both students and educators appreciate that review can help stabilize learning, time constraints result in a trade-off between acquiring new knowledge and preserving old knowledge. To use time efficiently, when should review take place? Experimental studies have shown benefits to long-term retention with spaced study, but little practical advice is available to students and educators about the optimal spacing of study. The dearth of advice is due to the challenge of conducting experimental studies of learning in educational settings, especially where material is introduced in blocks over the time frame of a semester. In this study, we turn to two established models of memory\textemdash ACT-R and MCM\textemdash to conduct simulation studies exploring the impact of study schedule on long-term retention. Based on the premise of a fixed time each week to review, converging evidence from the two models suggests that an optimal review schedule obtains significant benefits over haphazard (suboptimal) review schedules. Furthermore, we identify two scheduling heuristics that obtain near optimal review performance: (a) review the material from l-weeks back, and (b) review material whose predicted memory strength is closest to a particular threshold. The former has implications for classroom instruction and the latter for the design of digital tutors.},
  langid = {english},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2014/2014_Maximizing Students' Retention via Spaced Review_Khajah et al.pdf}
}

@article{kramarSynapticEvidenceEfficacy2012,
  title = {Synaptic Evidence for the Efficacy of Spaced Learning},
  author = {Kram{\'a}r, Enik{\"o} A. and Babayan, Alex H. and Gavin, Cristin F. and Cox, Conor D. and Jafari, Matiar and Gall, Christine M. and Rumbaugh, Gavin and Lynch, Gary},
  year = {2012},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  number = {13},
  pages = {5121--5126},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1120700109},
  abstract = {The superiority of spaced vs. massed training is a fundamental feature of learning. Here, we describe unanticipated timing rules for the production of long-term potentiation (LTP) in adult rat hippocampal slices that can account for one temporal segment of the spaced trials phenomenon. Successive bouts of naturalistic theta burst stimulation of field CA1 afferents markedly enhanced previously saturated LTP if spaced apart by 1 h or longer, but were without effect when shorter intervals were used. Analyses of F-actin-enriched spines to identify potentiated synapses indicated that the added LTP obtained with delayed theta trains involved recruitment of synapses that were ``missed'' by the first stimulation bout. Single spine glutamate-uncaging experiments confirmed that less than half of the spines in adult hippocampus are primed to undergo plasticity under baseline conditions, suggesting that intrinsic variability among individual synapses imposes a repetitive presentation requirement for maximizing the percentage of potentiated connections. We propose that a combination of local diffusion from initially modified spines coupled with much later membrane insertion events dictate that the repetitions be widely spaced. Thus, the synaptic mechanisms described here provide a neurobiological explanation for one component of a poorly understood, ubiquitous aspect of learning.},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2012/2012_Synaptic evidence for the efficacy of spaced learning_Kramár et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2012/2012_Synaptic evidence for the efficacy of spaced learning_Kramár et al2.pdf}
}

@article{landauerReinforcementConsolidation1969,
  title = {Reinforcement as Consolidation.},
  author = {Landauer, T. K.},
  year = {1969},
  journal = {Psychological Review},
  volume = {76},
  number = {1},
  pages = {82--96},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/h0026746},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1969/1969_Reinforcement as consolidation_Landauer.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1969/1969_Reinforcement as consolidation_Landauer2.pdf}
}

@book{leitnerLerntManLeben1974,
  title = {{So lernt man leben}},
  author = {Leitner, Sebastian},
  year = {1974},
  edition = {1. - 10. Tsd},
  publisher = {{Droemer-Knaur}},
  address = {{M\"unchen, Z\"urich}},
  isbn = {978-3-426-04571-8},
  langid = {german},
  keywords = {_tablet},
  file = {/Users/jarrettye/Zotero/storage/LPN7CQKK/1974_So lernt man leben_Leitner.pdf}
}

@article{lindseyImprovingStudentsLongterm2014,
  title = {Improving Students' Long-Term Knowledge Retention through Personalized Review},
  author = {Lindsey, Robert V. and Shroyer, Jeffery D. and Pashler, Harold and Mozer, Michael C.},
  year = {2014},
  month = mar,
  journal = {Psychological Science},
  volume = {25},
  number = {3},
  pages = {639--647},
  issn = {1467-9280},
  doi = {10.1177/0956797613504302},
  abstract = {Human memory is imperfect; thus, periodic review is required for the long-term preservation of knowledge and skills. However, students at every educational level are challenged by an ever-growing amount of material to review and an ongoing imperative to master new material. We developed a method for efficient, systematic, personalized review that combines statistical techniques for inferring individual differences with a psychological theory of memory. The method was integrated into a semester-long middle-school foreign-language course via retrieval-practice software. Using a cumulative exam administered after the semester's end, we compared time-matched review strategies and found that personalized review yielded a 16.5\% boost in course retention over current educational practice (massed study) and a 10.0\% improvement over a one-size-fits-all strategy for spaced study.},
  langid = {english},
  pmid = {24444515},
  keywords = {_tablet,adaptive scheduling,Adolescent,Bayes Theorem,Bayesian modeling,Child,classroom education,declarative memory,Education,educational psychology,Humans,individual differences,Individuality,Knowledge,Language,long-term memory,Memory; Long-Term,Retention; Psychology,Software,spacing effect,Test Taking Skills,Time Factors},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2014/2014_Improving students' long-term knowledge retention through personalized review_Lindsey et al.pdf}
}

@inproceedings{maassHowSpacingVariable2015,
  title = {How Spacing and Variable Retrieval Practice Affect the Learning of Statistics Concepts},
  booktitle = {Artificial Intelligence in Education},
  author = {Maass, Jaclyn K. and Pavlik, Philip I. and Hua, Henry},
  editor = {Conati, Cristina and Heffernan, Neil and Mitrovic, Antonija and Verdejo, M. Felisa},
  year = {2015},
  pages = {247--256},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {This research investigated key factors in learning conceptual material about statistics, and tested the effect of variability during retrieval practice. The goal was to build a model of learning for schedule-based interventions. Participants (n = 230) completed multiple reading and test trials with fill in the blank sentences about basic statistics concepts. The experiment was a 2 (trial type: read or drill) \texttimes{} 3 (learning trial spacing: wide medium, or narrow) \texttimes{} 2 (fill-in term during learning: variable or constant) \texttimes{} 2 (fill-in term during posttest: variable or constant) within-subjects design. The model of the results captures the data with recent and long-term components to explain posttest transfer and the testing and spacing effects. These results, and data on the conceptual confusions amongst statistical terms, are discussed with respect to implications for future intelligent learning systems.},
  isbn = {978-3-319-19773-9}
}

@article{maddoxRoleForgettingRate2011,
  title = {The Role of Forgetting Rate in Producing a Benefit of Expanded over Equal Spaced Retrieval in Young and Older Adults.},
  author = {Maddox, Geoffrey B. and Balota, David A. and Coane, Jennifer H. and Duchek, Janet M.},
  year = {2011},
  journal = {Psychology and Aging},
  volume = {26},
  number = {3},
  pages = {661--670},
  issn = {1939-1498, 0882-7974},
  doi = {10.1037/a0022942},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2011/2011_The role of forgetting rate in producing a benefit of expanded over equal_Maddox et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2011/2011_The role of forgetting rate in producing a benefit of expanded over equal_Maddox et al2.pdf}
}

@article{meltonSituationRespectSpacing1970,
  title = {The Situation with Respect to the Spacing of Repetitions and Memory},
  author = {Melton, Arthur W.},
  year = {1970},
  month = oct,
  journal = {Journal of Verbal Learning and Verbal Behavior},
  volume = {9},
  number = {5},
  pages = {596--606},
  issn = {0022-5371},
  doi = {10.1016/S0022-5371(70)80107-4},
  abstract = {The revival of interest in the effectiveness of spaced practice, as compared with massed practice, in learning is attributed to the abandonment of the constraints of serial and paired-associate list learning and the discovery of stable benefits from spaced practice in continuous paired-associate learning, short-term memory for individual items, and single-trial free-recall learning. Comments are made about the preceding symposium papers by Underwood, Waugh, and Greeno, and some data on the differential effects of spacing of repetitions in free-recall learning are introduced in an effort to assess the current state of fact and theory.},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1970/1970_The situation with respect to the spacing of repetitions and memory_Melton.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1970/1970_The situation with respect to the spacing of repetitions and memory_Melton2.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1970/1970_The situation with respect to the spacing of repetitions and memory_Melton3.pdf;/Users/jarrettye/Zotero/storage/94ZICIMR/S0022537170801074.html}
}

@inproceedings{pashlerPredictingOptimalSpacing2009,
  title = {Predicting the Optimal Spacing of Study: {{A}} Multiscale Context Model of Memory},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Pashler, Harold and Cepeda, Nicholas and Lindsey, Robert V and Vul, Ed and Mozer, Michael C},
  editor = {Bengio, Y. and Schuurmans, D. and Lafferty, J. and Williams, C. and Culotta, A.},
  year = {2009},
  volume = {22},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2009/2009_Predicting the optimal spacing of study_Pashler et al2.pdf}
}

@article{pavlikUsingModelCompute2008,
  title = {Using a Model to Compute the Optimal Schedule of Practice.},
  author = {Pavlik, Philip I. and Anderson, John R.},
  year = {2008},
  month = jun,
  journal = {Journal of Experimental Psychology: Applied},
  volume = {14},
  number = {2},
  pages = {101--117},
  issn = {1939-2192, 1076-898X},
  doi = {10.1037/1076-898X.14.2.101},
  abstract = {By balancing the spacing effect against the effects of recency and frequency, this paper explains how practice may be scheduled to maximize learning and retention. In an experiment, an optimized condition using an algorithm determined with this method was compared with other conditions. The optimized condition showed significant benefits with large effect sizes for both improved recall and recall latency. The optimization method achieved these benefits by using a modeling approach to develop a quantitative algorithm, which dynamically maximizes learning by determining for each item when the balance between increasing temporal spacing (that causes better long-term recall) and decreasing temporal spacing (that reduces the failure related time cost of each practice) means that the item is at the spacing interval where long-term gain per unit of practice time is maximal. As practice repetitions accumulate for each item, items become stable in memory and this optimal interval increases.},
  langid = {english},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2008/2008_Using a model to compute the optimal schedule of practice_Pavlik_Anderson.pdf}
}

@article{pimsleurMemorySchedule1967,
  title = {A {{Memory Schedule}}},
  author = {Pimsleur, Paul},
  year = {1967},
  month = feb,
  journal = {The Modern Language Journal},
  volume = {51},
  number = {2},
  pages = {73--75},
  issn = {00267902},
  doi = {10.1111/j.1540-4781.1967.tb06700.x},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1967/1967_A Memory Schedule_Pimsleur.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1967/1967_A Memory Schedule_Pimsleur2.pdf}
}

@book{qiu2020nndl,
  title = {神经网络与深度学习},
  author = {{邱锡鹏}},
  year = {2020},
  publisher = {{机械工业出版社}},
  address = {{北京}},
  isbn = {978-7-111-64968-7}
}

@article{raffertyFasterTeachingPOMDP2016,
  title = {Faster {{Teaching}} via {{POMDP Planning}}},
  author = {Rafferty, Anna N. and Brunskill, Emma and Griffiths, Thomas L. and Shafto, Patrick},
  year = {2016},
  month = aug,
  journal = {Cognitive Science},
  volume = {40},
  number = {6},
  pages = {1290--1332},
  issn = {0364-0213, 1551-6709},
  doi = {10.1111/cogs.12290},
  abstract = {Human and automated tutors attempt to choose pedagogical activities that will maximize student learning, informed by their estimates of the student's current knowledge. There has been substantial research on tracking and modeling student learning, but significantly less attention on how to plan teaching actions and how the assumed student model impacts the resulting plans. We frame the problem of optimally selecting teaching actions using a decision-theoretic approach and show how to formulate teaching as a partially observable Markov decision process planning problem. This framework makes it possible to explore how different assumptions about student learning and behavior should affect the selection of teaching actions. We consider how to apply this framework to concept learning problems, and we present approximate methods for finding optimal teaching actions, given the large state and action spaces that arise in teaching. Through simulations and behavioral experiments, we explore the consequences of choosing teacher actions under different assumed student models. In two concept-learning tasks, we show that this technique can accelerate learning relative to baseline performance.},
  langid = {english},
  keywords = {_tablet},
  file = {/Users/jarrettye/Zotero/storage/SVLNG9YG/2016_Faster Teaching via POMDP Planning_Rafferty et al.pdf}
}

@article{reaEffectExpandedMassed1970a,
  title = {The Effect of Expanded versus Massed Practice on the Retention of Multiplication Facts and Spelling Lists},
  author = {Rea, Cornelius and Modigliani, Vito},
  year = {1970},
  month = jan,
  journal = {Human Learning: Journal of Practical Research \& Applications},
  volume = {4},
  pages = {11--18},
  abstract = {To test the hypothesis that expanded practice is superior to massed practice in a classroom situation, a test series with expanded intervals to teach multiplication facts and spelling lists to 44 Grade 3 students, formed into massed and expanded groups based on their spelling and mathematical abilities, was conducted. Results show that, for multiplication facts, retention in the expanded series condition was almost twice that in the massed series condition; for spelling lists, a significant difference in the same direction was also obtained. These differences were obtained regardless of the level of ability of the Ss. It is suggested that an expanded test series not only engenders effective retention but also maintains a feeling of success throughout and that use of this type of series would therefore have obvious benefit if incorporated into remedial programs or used in learning centers. (23 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)}
}

@article{reddyAcceleratingHumanLearning2017,
  title = {Accelerating {{Human Learning}} with {{Deep Reinforcement Learning}}},
  author = {Reddy, Siddharth and Levine, Sergey and Dragan, Anca},
  year = {2017},
  journal = {University of California, Berkeley},
  pages = {9},
  abstract = {Guiding a student through a sequence of lessons and helping them retain knowledge is one of the central challenges in education. Online learning platforms like Khan Academy and Duolingo tackle this problem in part by using interaction data to estimate student proficiency and recommend content. While the literature proposes a variety of algorithms for modeling student learning, there is relatively little work on principled methods for sequentially choosing items for the student to review in order to maximize learning. We study this decision problem as an instance of reinforcement learning, and draw on recent advances in training deep neural networks to learn flexible and scalable teaching policies that select the next item to review. Our primary contribution is an analysis of a model-free review scheduling algorithm for spaced repetition systems that does not explicitly model the student, and instead learns a policy that directly operates on raw observations of the study history. As a preliminary study, we train and evaluate this method using a student simulator based on cognitive models of human memory. Results show that modelfree scheduling is competitive against widely-used heuristics like SuperMemo and the Leitner system on various learning objectives and student models.},
  langid = {english},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2017/2017_Accelerating Human Learning with Deep Reinforcement Learning_Reddy et al.pdf}
}

@inproceedings{reddyUnboundedHumanLearning2016,
  title = {Unbounded Human Learning: {{Optimal}} Scheduling for Spaced Repetition},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD}} International Conference on Knowledge Discovery and Data Mining},
  author = {Reddy, Siddharth and Labutov, Igor and Banerjee, Siddhartha and Joachims, Thorsten},
  year = {2016},
  series = {{{KDD}} '16},
  pages = {1815--1824},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2939672.2939850},
  abstract = {In the study of human learning, there is broad evidence that our ability to retain information improves with repeated exposure and decays with delay since last exposure. This plays a crucial role in the design of educational software, leading to a trade-off between teaching new material and reviewing what has already been taught. A common way to balance this trade-off is spaced repetition, which uses periodic review of content to improve long-term retention. Though spaced repetition is widely used in practice, e.g., in electronic flashcard software, there is little formal understanding of the design of these systems. Our paper addresses this gap in three ways. First, we mine log data from spaced repetition software to establish the functional dependence of retention on reinforcement and delay. Second, we use this memory model to develop a stochastic model for spaced repetition systems. We propose a queueing network model of the Leitner system for reviewing flashcards, along with a heuristic approximation that admits a tractable optimization problem for review scheduling. Finally, we empirically evaluate our queueing model through a Mechanical Turk experiment, verifying a key qualitative prediction of our model: the existence of a sharp phase transition in learning outcomes upon increasing the rate of new item introductions.},
  isbn = {978-1-4503-4232-2},
  keywords = {_tablet,human memory,queueing models,spaced repetition},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2016/2016_Unbounded human learning_Reddy et al.pdf}
}

@book{reisbergCognitionExploringScience2019,
  title = {Cognition: Exploring the Science of the Mind},
  shorttitle = {Cognition},
  author = {Reisberg, Daniel},
  year = {2019},
  edition = {Seventh Edition},
  publisher = {{W. W. Norton \& Company}},
  address = {{New York}},
  isbn = {978-0-393-66501-7 978-0-393-62413-7},
  lccn = {BF201 .R45 2019},
  keywords = {Cognitive psychology},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Book/2019/2019_Cognition_Reisberg.pdf}
}

@article{roedigerCriticalRoleRetrieval2011,
  title = {The Critical Role of Retrieval Practice in Long-Term Retention},
  author = {Roediger, Henry L. and Butler, Andrew C.},
  year = {2011},
  month = jan,
  journal = {Trends in Cognitive Sciences},
  volume = {15},
  number = {1},
  pages = {20--27},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2010.09.003},
  abstract = {Learning is usually thought to occur during episodes of studying, whereas retrieval of information on testing simply serves to assess what was learned. We review research that contradicts this traditional view by demonstrating that retrieval practice is actually a powerful mnemonic enhancer, often producing large gains in long-term retention relative to repeated studying. Retrieval practice is often effective even without feedback (i.e. giving the correct answer), but feedback enhances the benefits of testing. In addition, retrieval practice promotes the acquisition of knowledge that can be flexibly retrieved and transferred to different contexts. The power of retrieval practice in consolidating memories has important implications for both the study of memory and its application to educational practice.},
  langid = {english},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2011/2011_The critical role of retrieval practice in long-term retention_Roediger_Butler.pdf}
}

@inproceedings{settlesTrainableSpacedRepetition2016,
  title = {A {{Trainable Spaced Repetition Model}} for {{Language Learning}}},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Settles, Burr and Meeder, Brendan},
  year = {2016},
  month = aug,
  pages = {1848--1858},
  publisher = {{Association for Computational Linguistics}},
  address = {{Berlin, Germany}},
  doi = {10.18653/v1/P16-1174},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2016/2016_A Trainable Spaced Repetition Model for Language Learning_Settles_Meeder.pdf}
}

@phdthesis{sinhaUsingDeepReinforcement2019,
  title = {Using Deep Reinforcement Learning for Personalizing Review Sessions on E-Learning Platforms with Spaced Repetition},
  author = {Sinha, Sugandh},
  year = {2019},
  series = {{{TRITA-EECS-EX}}},
  number = {2019:217},
  pages = {82},
  abstract = {Spaced repetition is a learning technique in which content to be learned or memorized is reviewed multiple times with gaps in between for efficient memorization and practice of skills. Two of the most common systems used for providing spaced repetition on e-learning platforms are Leitner and SuperMemo systems. Previous work has demonstrated that deep reinforcement learning (DRL) is able to give performance comparable to traditional benchmarks such as Leitner and SuperMemo in a flashcard based setting with simulated learning behaviour. In this work, our main contribution has been introduction of two new reward functions to be used by the DRL agent. The first, is a realistically observable reward function that uses the average of sum of outcomes in a sample of exercises. The second uses a Long Short Term Memory (LSTM) network as a form of reward shaping to predict the rewards to be used by DRL agent. Our results indicate that in both cases, DRL performs well. But, when LSTM based reward function is used, the DRL agent learns good policy smoother and faster. Also, the quality of the student-tutor interaction data used to train the LSTM network displays an effect on the performance of the DRL agent.},
  school = {KTH, School of Electrical Engineering and Computer Science (EECS) / KTH, School of Electrical Engineering and Computer Science (EECS)},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2019/2019_Using deep reinforcement learning for personalizing review sessions on_Sinha.pdf}
}

@article{smithAssoziationsfestigkeitIhrerAbh1897,
  title = {Die {{Assoziationsfestigkeit}} in Ihrer {{Abh}}?Ngigkeit von Der {{Verteilung}} Der {{Wiederholungen}}.},
  shorttitle = {Die {{Assoziationsfestigkeit}} in Ihrer {{Abh}}?},
  author = {Smith, W. G.},
  year = {1897},
  journal = {Psychological Review},
  volume = {4},
  number = {6},
  pages = {682--684},
  issn = {0033-295X},
  doi = {10.1037/h0065777},
  langid = {english}
}

@article{smolenRightTimeLearn2016,
  title = {The Right Time to Learn: Mechanisms and Optimization of Spaced Learning},
  shorttitle = {The Right Time to Learn},
  author = {Smolen, Paul and Zhang, Yili and Byrne, John H.},
  year = {2016},
  month = feb,
  journal = {Nature reviews. Neuroscience},
  volume = {17},
  number = {2},
  pages = {77--88},
  issn = {1471-003X},
  doi = {10.1038/nrn.2015.18},
  abstract = {For many types of learning, spaced training, which involves repeated long inter-trial intervals, leads to more robust memory formation than does massed training, which involves short or no intervals. Several cognitive theories have been proposed to explain this superiority, but only recently have data begun to delineate the underlying cellular and molecular mechanisms of spaced training, and we review these theories and data here. Computational models of the implicated signalling cascades have predicted that spaced training with irregular inter-trial intervals can enhance learning. This strategy of using models to predict optimal spaced training protocols, combined with pharmacotherapy, suggests novel ways to rescue impaired synaptic plasticity and learning.},
  pmcid = {PMC5126970},
  pmid = {26806627},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2016/2016_The right time to learn_Smolen et al.pdf}
}

@article{tabibianEnhancingHumanLearning2019,
  title = {Enhancing Human Learning via Spaced Repetition Optimization},
  author = {Tabibian, Behzad and Upadhyay, Utkarsh and De, Abir and Zarezade, Ali and Sch{\"o}lkopf, Bernhard and {Gomez-Rodriguez}, Manuel},
  year = {2019},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {10},
  pages = {3988--3993},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1815156116},
  abstract = {Spaced repetition is a technique for efficient memorization which uses repeated review of content following a schedule determined by a spaced repetition algorithm to improve long-term retention. However, current spaced repetition algorithms are simple rule-based heuristics with a few hard-coded parameters. Here, we introduce a flexible representation of spaced repetition using the framework of marked temporal point processes and then address the design of spaced repetition algorithms with provable guarantees as an optimal control problem for stochastic differential equations with jumps. For two well-known human memory models, we show that, if the learner aims to maximize recall probability of the content to be learned subject to a cost on the reviewing frequency, the optimal reviewing schedule is given by the recall probability itself. As a result, we can then develop a simple, scalable online spaced repetition algorithm, MEMORIZE, to determine the optimal reviewing times. We perform a large-scale natural experiment using data from Duolingo, a popular language-learning online platform, and show that learners who follow a reviewing schedule determined by our algorithm memorize more effectively than learners who follow alternative schedules determined by several heuristics.},
  chapter = {Physical Sciences},
  copyright = {Copyright \textcopyright{} 2019 the Author(s). Published by PNAS.. http://creativecommons.org/licenses/by/4.0/This open access article is distributed under Creative Commons Attribution License 4.0 (CC BY).},
  langid = {english},
  pmid = {30670661},
  keywords = {_tablet,human learning,marked temporal point processes,memorization,spaced repetition,stochastic optimal control},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2019/2019_Enhancing human learning via spaced repetition optimization_Tabibian et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2019/false}
}

@article{tjImpactOnlineEducation2012,
  title = {Impact of Online Education on Intern Behaviour around {{Joint Commission National Patient Safety Goals}}: {{A}} Randomised Trial},
  shorttitle = {Impact of Online Education on Intern Behaviour around {{Joint Commission National Patient Safety Goals}}},
  author = {TJ, Shaw and LIM, Pernar and SE, Peyre and JF, Helfrick and K, Vogelgesang and E, Graydon-Baker and Y, Chretien and EJ, Brown and J, Nicholson and JJ, Heit and JP, Co and TK, Gandhi},
  year = {2012},
  month = oct,
  journal = {BMJ quality \& safety},
  volume = {21},
  number = {10},
  pages = {819--825},
  issn = {2044-5415},
  doi = {10.1136/bmjqs-2011-000702},
  abstract = {Purpose To compare the effectiveness of 2 types of online learning methodologies for improving the patient-safety behaviours mandated in the Joint Commission National Patient Safety Goals (NPSG). Methods This randomized controlled trial was conducted in 2010 at Massachusetts General Hospital (MGH) and Brigham \& Women's Hospital (BWH) in Boston USA. Incoming interns were randomised to either receive an online Spaced Education program (SE) consisting of cases and questions that reinforce over time, or a program consisting of an online slide show followed by a quiz (SQ). The outcome measures included NPSG-knowledge improvement, NPSG-compliant behaviors in a simulation scenario, self reported confidence in safety and quality, program acceptability and program relevance. Results Both online learning programs improved knowledge retention. On four out of seven survey items measuring satisfaction and self reported confidence, the proportion of SE interns responding positively was significantly higher (p{$<$}0.05) than the fraction of SQ interns. SE interns demonstrated a mean 4.79 (36.6\%) NPSG-compliant behaviors (out of 13 total), while SQ interns completed a mean 4.17 (32.0\%) (p=0.09). Among those in surgical fields, SE interns demonstrated a mean 5.67 (43.6\%) NPSG-compliant behaviors, while SQ interns completed a mean 2.33 (17.9\%) (p=0.015). Focus group data indicates that SE was more contextually relevant than SQ and significantly more engaging. Conclusion While both online methodologies improved knowledge surrounding the NPSG, SE was more contextually relevant to trainees and engaging. SE impacted more significantly on both self reported confidence and the behaviour of surgical residents in a simulated scenario.},
  pmcid = {PMC4068823},
  pmid = {22706930},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2012/2012_Impact of online education on intern behaviour around Joint Commission National_TJ et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2012/2012_Impact of online education on intern behaviour around Joint Commission National_TJ et al2.pdf}
}

@inproceedings{upadhyayDeepReinforcementLearning2018,
  title = {Deep {{Reinforcement Learning}} of {{Marked Temporal Point Processes}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Upadhyay, Utkarsh and De, Abir and Gomez Rodriguez, Manuel},
  year = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  keywords = {_tablet},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2018/2018_Deep Reinforcement Learning of Marked Temporal Point Processes_Upadhyay et al.pdf}
}

@article{wixtedGenuinePowerCurves1997,
  title = {Genuine Power Curves in Forgetting: {{A}} Quantitative Analysis of Individual Subject Forgetting Functions},
  shorttitle = {Genuine Power Curves in Forgetting},
  author = {Wixted, John T. and Ebbesen, Ebbe B.},
  year = {1997},
  month = sep,
  journal = {Memory \& Cognition},
  volume = {25},
  number = {5},
  pages = {731--739},
  issn = {1532-5946},
  doi = {10.3758/BF03211316},
  abstract = {Wixted and Ebbesen (1991) showed that forgetting functions produced by a variety of procedures are often well described by the power function, at-b, where a and b are free parameters. However, all of their analyses were based on data arithmetically averaged over subjects. R. B. Anderson and Tweney (1997) argue that the power law of forgetting may be an artifact of arithmetically averaging individual subject forgetting functions that are truly exponential in form and that geometric averaging would avoid this potential problem. We agree that researchers should always be cognizant of the possibility of averaging artifacts, but we also show that our conclusions about the form of forgetting remain unchanged (and goodness-of-fit statistics are scarcely affected by) whether arithmetic or geometric averaging is used. In addition, an analysis of individual subject forgetting functions shows that they, too, are described much better by a power function than by an exponential.},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1997/1997_Genuine power curves in forgetting_Wixted_Ebbesen2.pdf}
}

@article{wixtedWickelgrenPowerLaw2007,
  title = {The {{Wickelgren Power Law}} and the {{Ebbinghaus Savings Function}}},
  author = {Wixted, John T. and Carpenter, Shana K.},
  year = {2007},
  month = feb,
  journal = {Psychological Science},
  volume = {18},
  number = {2},
  pages = {133--134},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2007.01862.x},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2007/2007_The Wickelgren Power Law and the Ebbinghaus Savings Function_Wixted_Carpenter.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/2007/2007_The Wickelgren Power Law and the Ebbinghaus Savings Function_Wixted_Carpenter2.pdf}
}

@article{woiniakOptimizationRepetitionSpacing1994,
  title = {Optimization of Repetition Spacing in the Practice of Learning},
  author = {Woiniak, Piotr A and Gorzelanczyk, Edward J},
  year = {1994},
  pages = {4},
  abstract = {A universal formula for computing inter-repetition intervals in paired-associate learning has been determined for the knowledge retention level of 95\%. It is claimed that the formula could be used in the practice of learning for a wide range of subjects, regardless individual learner's capacity.},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Journal Article/1994/1994_Optimization of repetition spacing in the practice of learning_Woiniak_Gorzelanczyk2.pdf}
}

@article{wolfWantRememberEverything2008,
  title = {Want to {{Remember Everything You}}'ll {{Ever Learn}}? {{Surrender}} to {{This Algorithm}}},
  shorttitle = {Want to {{Remember Everything You}}'ll {{Ever Learn}}?},
  author = {Wolf, Gary},
  year = {2008},
  journal = {Wired},
  issn = {1059-1028},
  abstract = {Illustration: Steven Wilson The winter sun sets in mid-afternoon in Kolobrzeg, Poland, but the early twilight does not deter people from taking their regular outdoor promenade. Bundled up in parkas with fur-trimmed hoods, strolling hand in mittened hand along the edge of the Baltic Sea, off-season tourists from Germany stop openmouthed when they see a tall, [\ldots ]},
  chapter = {tags},
  langid = {american},
  keywords = {health,magazine-16.05},
  file = {/Users/jarrettye/Zotero/storage/6XP865PJ/ff-wozniak.html}
}

@misc{wozniakOptimizationLearning1990,
  title = {Optimization of {{Learning}}},
  author = {Wozniak, Piotr A.},
  year = {1990},
  howpublished = {http://super-memory.com/english/ol.htm},
  file = {/Users/jarrettye/Zotero/storage/NAQBIRD2/Wozniak - 1990 - Optimization of Learning.html}
}

@inproceedings{yanceySleepingRecoveringBandit2020,
  title = {A {{Sleeping}}, {{Recovering Bandit Algorithm}} for {{Optimizing Recurring Notifications}}},
  booktitle = {Proceedings of the 26th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Yancey, Kevin P. and Settles, Burr},
  year = {2020},
  month = aug,
  pages = {3008--3016},
  publisher = {{ACM}},
  address = {{Virtual Event CA USA}},
  doi = {10.1145/3394486.3403351},
  abstract = {Many online and mobile applications rely on daily emails and push notifications to increase and maintain user engagement. The multiarmed bandit approach provides a useful framework for optimizing the content of these notifications, but a number of complications (such as novelty effects and conditional eligibility) make conventional bandit algorithms unsuitable in practice. In this paper, we introduce the Recovering Difference Softmax Algorithm to address the particular challenges of this problem domain, and use it to successfully optimize millions of daily reminders for the online language-learning app Duolingo. This lead to a 0.5 \% increase in total daily active users (DAUs) and a 2 \% increase in new user retention over a strong baseline. We provide technical details of its design and deployment, and demonstrate its efficacy through both offline and online evaluation experiments.},
  isbn = {978-1-4503-7998-4},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2020/2020_A Sleeping, Recovering Bandit Algorithm for Optimizing Recurring Notifications_Yancey_Settles.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2020/2020_A Sleeping, Recovering Bandit Algorithm for Optimizing Recurring Notifications_Yancey_Settles2.pdf}
}

@inproceedings{yangTADSLearningTimeaware2020,
  title = {{{TADS}}: {{Learning}} Time-Aware Scheduling Policy with Dyna-Style Planning for Spaced Repetition},
  booktitle = {Proceedings of the 43rd International {{ACM SIGIR}} Conference on Research and Development in Information Retrieval},
  author = {Yang, Zhengyu and Shen, Jian and Liu, Yunfei and Yang, Yang and Zhang, Weinan and Yu, Yong},
  year = {2020},
  series = {{{SIGIR}} '20},
  pages = {1917--1920},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3397271.3401316},
  abstract = {Spaced repetition technique aims at improving long-term memory retention for human students by exploiting repeated, spaced reviews of learning contents. The study of spaced repetition focuses on designing an optimal policy to schedule the learning contents. To the best of our knowledge, none of the existing methods based on reinforcement learning take into account the varying time intervals between two adjacent learning events of the student, which, however, are essential to determine real-world schedule. In this paper, we aim to learn a scheduling policy that fully exploits the varying time interval information with high sample efficiency. We propose the Time-Aware scheduler with Dyna-Style planning (TADS) approach: a sample-efficient reinforcement learning framework for realistic spaced repetition. TADS learns a Time-LSTM policy to select an optimal content according to the student's whole learning history and the time interval since the last learning event. Besides, Dyna-style planning is integrated into TADS to further improve the sample efficiency. We evaluate our approach on three environments built from synthetic data and real-world data based on well-recognized cognitive models. Empirical results demonstrate that TADS achieves superior performance against state-of-the-art algorithms.},
  isbn = {978-1-4503-8016-4},
  keywords = {human memory,reinforcement learning,spaced repetition},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Book Section/2020/2020_TADS_Yang et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2020/2020_TADS_Yang et al.pdf}
}

@inproceedings{yeckehzaareSpacedInterleavedRetrieval2019,
  title = {A {{Spaced}}, {{Interleaved Retrieval Practice Tool}} That Is {{Motivating}} and {{Effective}}},
  booktitle = {Proceedings of the 2019 {{ACM Conference}} on {{International Computing Education Research}}},
  author = {YeckehZaare, Iman and Resnick, Paul and Ericson, Barbara},
  year = {2019},
  month = jul,
  pages = {71--79},
  publisher = {{ACM}},
  address = {{Toronto ON Canada}},
  doi = {10.1145/3291279.3339411},
  isbn = {978-1-4503-6185-9},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2019/2019_A Spaced, Interleaved Retrieval Practice Tool that is Motivating and Effective_YeckehZaare et al3.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2019/2019_A Spaced, Interleaved Retrieval Practice Tool that is Motivating and Effective_YeckehZaare et al4.pdf}
}

@inproceedings{zaidiAdaptiveForgettingCurves2020,
  title = {Adaptive {{Forgetting Curves}} for {{Spaced Repetition Language Learning}}},
  booktitle = {Artificial {{Intelligence}} in {{Education}}},
  author = {Zaidi, Ahmed and Caines, Andrew and Moore, Russell and Buttery, Paula and Rice, Andrew},
  editor = {Bittencourt, Ig Ibert and Cukurova, Mutlu and Muldner, Kasia and Luckin, Rose and Mill{\'a}n, Eva},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {358--363},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-52240-7_65},
  abstract = {The forgetting curve has been extensively explored by psychologists, educationalists and cognitive scientists alike. In the context of Intelligent Tutoring Systems, modelling the forgetting curve for each user and knowledge component (e.g. vocabulary word) should enable us to develop optimal revision strategies that counteract memory decay and ensure long-term retention. In this study we explore a variety of forgetting curve models incorporating psychological and linguistic features, and we use these models to predict the probability of word recall by learners of English as a second language. We evaluate the impact of the models and their features using data from an online vocabulary teaching platform and find that word complexity is a highly informative feature which may be successfully learned by a neural network model.},
  isbn = {978-3-030-52240-7},
  langid = {english},
  keywords = {_tablet,Adaptive learning,Forgetting curve,Language learning,Neural networks,Spaced repetition},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2020/2020_Adaptive Forgetting Curves for Spaced Repetition Language Learning_Zaidi et al.pdf}
}

@inproceedings{zhaoMaximizingCumulativeUser2020,
  title = {Maximizing {{Cumulative User Engagement}} in {{Sequential Recommendation}}: {{An Online Optimization Perspective}}},
  shorttitle = {Maximizing {{Cumulative User Engagement}} in {{Sequential Recommendation}}},
  booktitle = {Proceedings of the 26th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Zhao, Yifei and Zhou, Yu-Hang and Ou, Mingdong and Xu, Huan and Li, Nan},
  year = {2020},
  month = aug,
  pages = {2784--2792},
  publisher = {{ACM}},
  address = {{Virtual Event CA USA}},
  doi = {10.1145/3394486.3403329},
  abstract = {To maximize cumulative user engagement (e.g. cumulative clicks) in sequential recommendation, it is often needed to tradeoff two potentially conflicting objectives, that is, pursuing higher immediate user engagement (e.g., click-through rate) and encouraging user browsing (i.e., more items exposured). Existing works often study these two tasks separately, thus tend to result in sub-optimal results. In this paper, we study this problem from an online optimization perspective, and propose a flexible and practical framework to explicitly tradeoff longer user browsing length and high immediate user engagement. Specifically, by considering items as actions, user's requests as states and user leaving as an absorbing state, we formulate each user's behavior as a personalized Markov decision process (MDP), and the problem of maximizing cumulative user engagement is reduced to a stochastic shortest path (SSP) problem. Meanwhile, with immediate user engagement and quit probability estimation, it is shown that the SSP problem can be efficiently solved via dynamic programming. Experiments on real-world datasets demonstrate the effectiveness of the proposed approach. Moreover, this approach is deployed at a large E-commerce platform, achieved over 7\% improvement of cumulative clicks.},
  isbn = {978-1-4503-7998-4},
  langid = {english},
  file = {/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2020/2020_Maximizing Cumulative User Engagement in Sequential Recommendation_Zhao et al.pdf;/Users/jarrettye/Library/Mobile Documents/com~apple~CloudDocs/zotfile/Conference Paper/2020/2020_Maximizing Cumulative User Engagement in Sequential Recommendation_Zhao et al2.pdf}
}


